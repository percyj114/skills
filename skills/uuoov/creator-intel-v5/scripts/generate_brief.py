#!/usr/bin/env python3
"""
åˆ›é€ è€…æƒ…æŠ¥ V5 - å·¥ç¨‹å¸ˆè§†è§’ç»ˆæç‰ˆ
ä¸¥ç¦VCè¯æœ¯ï¼Œåªå…³æ³¨åº•å±‚æŠ€æœ¯å®ç°
"""

import json
import os
import sys
from datetime import datetime
import feedparser
import re
import requests

CONFIG_DIR = os.path.expanduser("~/.openclaw/creator-intel")
HISTORY_FILE = os.path.join(CONFIG_DIR, "history.json")
TAVILY_API_KEY = "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"

# V5 å·¥ç¨‹å¸ˆè§†è§’æœç´¢å…³é”®è¯ï¼ˆå»å•†ä¸šåŒ–ï¼Œé‡æŠ€æœ¯ï¼‰
ENGINEER_QUERIES = [
    # å¼€æºé¡¹ç›®ä¸GitHubéœ¸æ¦œ
    "GitHub trending robotics open source 2026",
    "open source surgical robot hardware design",
    "brain computer interface BCI open source project",
    "humanoid robot open source hardware GitHub",
    
    # ç¡¬æ ¸æŠ€æœ¯åŸç†è§£æ
    "MoE mixture of experts architecture medical AI",
    "sparse attention mechanism robotics",
    "flow matching diffusion model technical",
    "neural radiance field NeRF medical imaging",
    
    # æå®¢ç¡¬ä»¶ä¸åˆ›æ–°äº¤äº’
    "ESP32 medical device prototype Kickstarter",
    "Raspberry Pi 5 robotics project",
    "e-ink display wearable health monitoring",
    "flexible electronics brain implant material",
    
    # ç®—æ³•ä¸æ¶æ„çªç ´
    "transformer alternative architecture 2026",
    "edge AI inference optimization robotics",
    "neuromorphic computing chip medical",
]

# å›½å†…æŠ€æœ¯å‘RSS
CN_TECH_SOURCES = [
    {"name": "æœºå™¨ä¹‹å¿ƒ", "url": "https://www.jiqizhixin.com/rss", "cat": "tech"},
    {"name": "é‡å­ä½", "url": "https://www.qbitai.com/feed", "cat": "tech"},
    {"name": "å¼€æºä¸­å›½", "url": "https://www.oschina.net/news/rss", "cat": "opensource"},
]

# V5 é»‘åå•ï¼ˆå•†ä¸šåŒ–å™ªéŸ³ï¼‰
BLACKLIST = [
    r'èèµ„.*äº¿', r'ä¼°å€¼.*äº¿', r'å•†ä¸šåŒ–.*è½åœ°', r'è§„æ¨¡åŒ–.*éƒ¨ç½²',
    r'æ‹“å±•.*å¸‚åœº', r'æˆ˜ç•¥.*å‘å¸ƒ', r'ç”Ÿæ€.*å¸ƒå±€', r'èµ›é“.*é¾™å¤´',
    r'é¢†è·‘.*è¡Œä¸š', r'é¢ è¦†.*ä¼ ç»Ÿ', r'é©å‘½æ€§.*çªç ´', r'é‡ç£….*å‘å¸ƒ',
    r'iPhone', r'Samsung', r'æ¶ˆè´¹.*ç”µå­', r'æ˜¥æ™š', r'è¶…çº§ç¢—',
]

# V5 ç™½åå•ï¼ˆæŠ€æœ¯ä¿¡å·ï¼‰
WHITELIST = [
    r'å¼€æº', r'GitHub', r'æ¶æ„', r'ç®—æ³•', r'æ¨¡å‹.*å‚æ•°', 
    r'MoE', r'ç¨€ç–æ³¨æ„åŠ›', r'æµåŒ¹é…', r'æ‰©æ•£.*æ¨¡å‹',
    r'æ‰‹æœ¯æœºå™¨äºº', r'è„‘æœºæ¥å£', r'BCI', r'çµå·§æ‰‹',
    r'ESP32', r'æ ‘è“æ´¾', r'Raspberry', r'NVMe', r'PCIe',
    r'è¾¹ç¼˜.*æ¨ç†', r'å®æ—¶.*æ¨ç†', r'ç¥ç»ç½‘ç»œ', r'èŠ¯ç‰‡.*æ¶æ„',
]

def tavily_search(query, max_results=3):
    """Tavily API æœç´¢æŠ€æœ¯å‘å†…å®¹"""
    try:
        url = "https://api.tavily.com/search"
        headers = {"Content-Type": "application/json"}
        payload = {
            "api_key": TAVILY_API_KEY,
            "query": query,
            "search_depth": "advanced",
            "include_answer": False,
            "max_results": max_results,
            "include_domains": [
                "github.com", "arxiv.org", "hackaday.com", "kickstarter.com",
                "ieee.org", "spectrum.ieee.org", "embedded.com", "raspberrypi.com"
            ]
        }
        
        resp = requests.post(url, json=payload, headers=headers, timeout=30)
        data = resp.json()
        
        results = []
        for item in data.get("results", []):
            title = item.get("title", "")
            url = item.get("url", "")
            content = item.get("content", "")
            
            # V5 è¿‡æ»¤ï¼šé™æƒçº¯å•†ä¸šåŒ–å†…å®¹
            if any(re.search(p, title + content, re.I) for p in BLACKLIST):
                if not any(re.search(p, title + content, re.I) for p in WHITELIST):
                    continue
            
            results.append({
                "title": title,
                "url": url,
                "content": content,
                "source": "tavily"
            })
        
        return results
    except Exception as e:
        print(f"Tavily æœç´¢å¤±è´¥: {e}")
        return []

def clean_title(title):
    """æ¸…æ´—æ ‡é¢˜"""
    patterns = [
        r'\|.*36æ°ª.*', r'\|.*æœºå™¨ä¹‹å¿ƒ.*', r'\|.*é‡å­ä½.*',
        r'é‡ç£….*', r'æ·±åº¦.*', r'ç‹¬å®¶.*', r'é¦–å‘.*',
        r'GitHub - ', r'GitHub: ', r'Kickstarter - ',
    ]
    for p in patterns:
        title = re.sub(p, '', title)
    return title.strip()

def rewrite_engineer_title(original):
    """V5 å·¥ç¨‹å¸ˆè§†è§’é‡å†™æ ‡é¢˜"""
    title = clean_title(original)
    
    # æå–æ ¸å¿ƒæŠ€æœ¯å®ä½“
    tech_entities = [
        (r'(MoE|Mixture of Experts)', 'MoEæ¶æ„'),
        (r'(sparse attention|ç¨€ç–æ³¨æ„åŠ›)', 'ç¨€ç–æ³¨æ„åŠ›'),
        (r'(flow matching|æµåŒ¹é…)', 'æµåŒ¹é…'),
        (r'(diffusion|æ‰©æ•£æ¨¡å‹)', 'æ‰©æ•£æ¨¡å‹'),
        (r'(transformer|Transformer)', 'Transformer'),
        (r'(ESP32|esp32)', 'ESP32'),
        (r'(Raspberry Pi|raspberry)', 'æ ‘è“æ´¾'),
        (r'(NVMe|nvme)', 'NVMe'),
        (r'(PCIe|pcie)', 'PCIe'),
        (r'(GitHub|github)', 'GitHub'),
        (r'(surgical robot|æ‰‹æœ¯æœºå™¨äºº)', 'æ‰‹æœ¯æœºå™¨äºº'),
        (r'(BCI|brain.?computer|è„‘æœº)', 'è„‘æœºæ¥å£'),
        (r'(humanoid|äººå½¢æœºå™¨äºº)', 'äººå½¢æœºå™¨äºº'),
        (r'(flexible electronics|æŸ”æ€§ç”µå­)', 'æŸ”æ€§ç”µå­'),
        (r'(neuromorphic|ç¥ç»å½¢æ€)', 'ç¥ç»å½¢æ€èŠ¯ç‰‡'),
    ]
    
    core_tech = ""
    for pattern, name in tech_entities:
        if re.search(pattern, title, re.I):
            core_tech = name
            break
    
    # æå–åŠ¨ä½œ
    actions = [
        (r'(å¼€æº|open.?source)', 'å¼€æº'),
        (r'(å‘å¸ƒ|release|launch)', 'å‘å¸ƒ'),
        (r'(å®ç°|achieve|reach)', 'å®ç°'),
        (r'(é‡‡ç”¨|adopt|use)', 'é‡‡ç”¨'),
        (r'(ä¼˜åŒ–|optimize|improve)', 'ä¼˜åŒ–'),
    ]
    
    action = ""
    for pattern, name in actions:
        if re.search(pattern, title, re.I):
            action = name
            break
    
    # æå–æ€§èƒ½å‚æ•°
    perf_match = re.search(r'(\d+[\d\s]*(?:tokens?/s|Hz|GB|MB/s|fps|ms|å‚æ•°|B|M))', title, re.I)
    perf = perf_match.group(1) if perf_match else ""
    
    # ç»„åˆï¼šæŠ€æœ¯ + åŠ¨ä½œ + æ€§èƒ½
    parts = [p for p in [core_tech, action, perf] if p]
    if len(parts) >= 2:
        rewritten = f"{parts[0]}{parts[1]}" + (f"è¾¾{parts[2]}" if len(parts) > 2 else "")
    elif len(parts) == 1:
        rewritten = parts[0] + "æŠ€æœ¯çªç ´"
    else:
        rewritten = title[:18] + "â€¦" if len(title) > 18 else title
    
    # æ§åˆ¶é•¿åº¦
    if len(rewritten) > 22:
        rewritten = rewritten[:20] + "â€¦"
    
    return rewritten

def extract_tech_summary(content):
    """V5 æå–ç¡¬æ ¸æŠ€æœ¯æ‘˜è¦ï¼ˆè‡³å°‘2ä¸ªæŠ€æœ¯åè¯/å‚æ•°ï¼‰"""
    text = content or ""
    
    # æ‰¾æ¶æ„/ç®—æ³•æè¿°
    arch_patterns = [
        r'(?:é‡‡ç”¨|ä½¿ç”¨|åŸºäº|é€šè¿‡)([^ï¼Œã€‚]{8,40})(?:æ¶æ„|ç®—æ³•|æœºåˆ¶|æŠ€æœ¯)',
        r'((?:MoE|sparse attention|flow matching|diffusion|transformer)[^ï¼Œã€‚]{5,30})',
        r'((?:PCIe|NVMe|ESP32|ARM|RISC-V)[^ï¼Œã€‚]{5,25})',
    ]
    
    tech_detail = ""
    for pattern in arch_patterns:
        match = re.search(pattern, text, re.I)
        if match:
            tech_detail = match.group(1) if match.lastindex else match.group(0)
            break
    
    # æ‰¾æ€§èƒ½å‚æ•°
    perf_patterns = [
        r'(\d+[\d\s]*(?:tokens?/s|Hz|GB/s|MB/s|fps|ms|å¾®ç§’|çº³ç§’))',
        r'(\d+[\d\s]*(?:äº¿|ä¸‡|B|M|å‚æ•°))',
        r'(å»¶è¿Ÿ|é€Ÿåº¦|ååé‡|å¸¦å®½)(?:é™ä½|æå‡|è¾¾åˆ°)([^ï¼Œã€‚]{3,15})',
    ]
    
    perf_detail = ""
    for pattern in perf_patterns:
        match = re.search(pattern, text, re.I)
        if match:
            perf_detail = match.group(0)
            break
    
    # æ‰¾è§£å†³çš„é—®é¢˜/åº”ç”¨åœºæ™¯
    problem_patterns = [
        r'(?:è§£å†³äº†|æ”»å…‹äº†|é’ˆå¯¹)([^ï¼Œã€‚]{8,30})(?:é—®é¢˜|ç—›ç‚¹|ç“¶é¢ˆ)',
        r'(?:æ”¯æŒ|å®ç°)([^ï¼Œã€‚]{5,25})(?:åŠŸèƒ½|èƒ½åŠ›|æ“ä½œ)',
    ]
    
    problem_detail = ""
    for pattern in problem_patterns:
        match = re.search(pattern, text, re.I)
        if match:
            problem_detail = match.group(1) if match.lastindex else match.group(0)
            break
    
    # ç»„åˆæ‘˜è¦ï¼ˆå¿…é¡»åŒ…å«è‡³å°‘2ä¸ªæŠ€æœ¯å…ƒç´ ï¼‰
    summary_parts = []
    if tech_detail:
        summary_parts.append(tech_detail)
    if perf_detail:
        summary_parts.append(f"å…³é”®æ€§èƒ½ï¼š{perf_detail}")
    if problem_detail and len(summary_parts) < 2:
        summary_parts.append(f"åº”ç”¨åœºæ™¯ï¼š{problem_detail}")
    
    if len(summary_parts) >= 2:
        summary = "ï¼›".join(summary_parts[:2])
    elif len(summary_parts) == 1:
        # è¡¥å……æŠ€æœ¯ç»†èŠ‚
        summary = summary_parts[0] + "ï¼Œå®ç°åº•å±‚æ¶æ„çªç ´"
    else:
        # å¤‡é€‰ï¼šæå–å‰80å­—
        summary = text[:70] + "â€¦" if len(text) > 70 else text
    
    return summary[:75] + "â€¦" if len(summary) > 75 else summary

def fetch_cn_tech_news(source, history):
    """æŠ“å–å›½å†…æŠ€æœ¯å‘RSS"""
    try:
        feed = feedparser.parse(source["url"])
        news_list = []
        
        for entry in feed.entries[:5]:
            url = entry.get('link', '')
            title = entry.get('title', '')
            
            if not url or not title or url in history.get("sent_urls", []):
                continue
            
            # V5 è¿‡æ»¤å•†ä¸šåŒ–å™ªéŸ³
            if any(re.search(p, title, re.I) for p in BLACKLIST):
                if not any(re.search(p, title, re.I) for p in WHITELIST):
                    continue
            
            content = entry.get('description', '') or entry.get('summary', '')
            
            # é‡å†™æ ‡é¢˜
            new_title = rewrite_engineer_title(title)
            
            # æå–æŠ€æœ¯æ‘˜è¦
            summary = extract_tech_summary(content)
            if not summary or len(summary) < 15:
                continue
            
            news_list.append({
                "title": new_title,
                "summary": summary,
                "url": url,
                "region": "cn",
                "source": "rss"
            })
        
        return news_list
    except:
        return []

def load_history():
    if os.path.exists(HISTORY_FILE):
        with open(HISTORY_FILE, 'r', encoding='utf-8') as f:
            data = json.load(f)
            data.setdefault("sent_urls", [])
            return data
    return {"sent_urls": []}

def save_history(history):
    os.makedirs(CONFIG_DIR, exist_ok=True)
    with open(HISTORY_FILE, 'w', encoding='utf-8') as f:
        json.dump(history, f, ensure_ascii=False, indent=2)

def generate_intel():
    """V5 å·¥ç¨‹å¸ˆè§†è§’ç”Ÿæˆæƒ…æŠ¥"""
    history = load_history()
    
    # 1. Tavily æœç´¢å›½é™…æŠ€æœ¯å‘å†…å®¹ï¼ˆä¼˜å…ˆï¼‰
    global_news = []
    for query in ENGINEER_QUERIES[:4]:  # æœç´¢4ä¸ªå…³é”®è¯
        results = tavily_search(query, max_results=2)
        for item in results:
            # é‡å†™æ ‡é¢˜
            new_title = rewrite_engineer_title(item["title"])
            # æå–æŠ€æœ¯æ‘˜è¦
            summary = extract_tech_summary(item["content"])
            
            global_news.append({
                "title": new_title,
                "summary": summary,
                "url": item["url"],
                "region": "global"
            })
    
    # 2. å›½å†…æŠ€æœ¯RSS
    cn_news = []
    for source in CN_TECH_SOURCES:
        news = fetch_cn_tech_news(source, history)
        cn_news.extend(news)
    
    # åˆå¹¶å¹¶å»é‡
    all_news = global_news + cn_news
    seen_urls = set()
    unique_news = []
    for n in all_news:
        if n["url"] not in seen_urls and n["url"] not in history.get("sent_urls", []):
            unique_news.append(n)
            seen_urls.add(n["url"])
    
    # V5 ä¼˜å…ˆæŠ€æœ¯å‘å†…å®¹ï¼ˆå›½é™…ä¼˜å…ˆï¼‰
    selected = unique_news[:6]
    
    if len(selected) < 3:
        return "[è­¦å‘Š] æœªè·å–åˆ°è¶³å¤Ÿçš„ç¡¬æ ¸æŠ€æœ¯æƒ…æŠ¥"
    
    # V5 ä¸¥æ ¼æ ¼å¼è¾“å‡º
    today = datetime.now().strftime("%Y-%m-%d")
    lines = [f"[{today}] åˆ›é€ è€…æƒ…æŠ¥ ğŸŒ", ""]
    
    for news in selected:
        # Emoji
        t = news["title"].lower()
        if any(kw in t for kw in ["github", "å¼€æº", "open source"]):
            emoji = "ğŸ“¦"
        elif any(kw in t for kw in ["æ¶æ„", "ç®—æ³•", "model", "transformer", "diffusion"]):
            emoji = "âš›ï¸"
        elif any(kw in t for kw in ["esp32", "raspberry", "æ ‘è“æ´¾", "nvme", "pcie"]):
            emoji = "ğŸ› ï¸"
        elif any(kw in t for kw in ["æ‰‹æœ¯æœºå™¨äºº", "surgical", "æœºå™¨äºº"]):
            emoji = "ğŸ”¬"
        elif any(kw in t for kw in ["è„‘æœº", "bci", "brain"]):
            emoji = "ğŸ§ "
        else:
            emoji = "ğŸ’¡"
        
        # V5 æ ¼å¼
        lines.append(f"> {emoji} {news['title']}")
        lines.append(f"> æ‘˜è¦ï¼š{news['summary']}")
        lines.append("")
        lines.append("")
        
        history["sent_urls"].append(news["url"])
    
    save_history(history)
    return "\n".join(lines)

if __name__ == "__main__":
    intel = generate_intel()
    print(intel)
