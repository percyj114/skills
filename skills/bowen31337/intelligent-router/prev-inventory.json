{
  "scan_timestamp": "2026-02-24T22:34:15.449183",
  "total_models": 40,
  "available_models": 26,
  "unavailable_models": 14,
  "providers": {
    "ollama": {
      "name": "ollama",
      "models": [
        {
          "id": "llama3.2-vision:11b",
          "name": "Llama 3.2 Vision 11B",
          "provider": "ollama",
          "tier": "SIMPLE",
          "capabilities": [],
          "cost": {
            "input": 0,
            "output": 0,
            "cacheRead": 0,
            "cacheWrite": 0
          },
          "context_window": 128000,
          "agentic": false,
          "available": false,
          "latency": 0.002,
          "error": "HTTP 404: {\"error\":{\"message\":\"model 'llama3.2-vision:11b' not found\",\"type\":\"api_error\",\"param\":null,\"code\":null}}\n",
          "response_preview": null,
          "timestamp": "2026-02-24T22:34:15.461073"
        },
        {
          "id": "llama3.2:3b",
          "name": "Llama 3.2 3B",
          "provider": "ollama",
          "tier": "SIMPLE",
          "capabilities": [],
          "cost": {
            "input": 0,
            "output": 0,
            "cacheRead": 0,
            "cacheWrite": 0
          },
          "context_window": 128000,
          "agentic": false,
          "available": false,
          "latency": 0.0,
          "error": "HTTP 404: {\"error\":{\"message\":\"model 'llama3.2:3b' not found\",\"type\":\"api_error\",\"param\":null,\"code\":null}}\n",
          "response_preview": null,
          "timestamp": "2026-02-24T22:34:15.461774"
        },
        {
          "id": "qwen2.5:1.5b",
          "name": "Qwen 2.5 1.5B",
          "provider": "ollama",
          "tier": "SIMPLE",
          "capabilities": [],
          "cost": {
            "input": 0,
            "output": 0,
            "cacheRead": 0,
            "cacheWrite": 0
          },
          "context_window": 32768,
          "agentic": false,
          "available": true,
          "latency": 0.12,
          "error": null,
          "response_preview": "Hello! It seems like",
          "timestamp": "2026-02-24T22:34:15.582080"
        },
        {
          "id": "qwen2.5:32b",
          "name": "Qwen 2.5 32B",
          "provider": "ollama",
          "tier": "SIMPLE",
          "capabilities": [],
          "cost": {
            "input": 0,
            "output": 0,
            "cacheRead": 0,
            "cacheWrite": 0
          },
          "context_window": 32768,
          "agentic": false,
          "available": false,
          "latency": 0.001,
          "error": "HTTP 404: {\"error\":{\"message\":\"model 'qwen2.5:32b' not found\",\"type\":\"api_error\",\"param\":null,\"code\":null}}\n",
          "response_preview": null,
          "timestamp": "2026-02-24T22:34:15.582889"
        },
        {
          "id": "llama3.3",
          "name": "Llama 3.3",
          "provider": "ollama",
          "tier": "SIMPLE",
          "capabilities": [],
          "cost": {
            "input": 0,
            "output": 0,
            "cacheRead": 0,
            "cacheWrite": 0
          },
          "context_window": 128000,
          "agentic": false,
          "available": false,
          "latency": 0.001,
          "error": "HTTP 404: {\"error\":{\"message\":\"model 'llama3.3' not found\",\"type\":\"api_error\",\"param\":null,\"code\":null}}\n",
          "response_preview": null,
          "timestamp": "2026-02-24T22:34:15.583597"
        },
        {
          "id": "qwen2-vl:7b",
          "name": "Qwen 2 VL 7B",
          "provider": "ollama",
          "tier": "SIMPLE",
          "capabilities": [],
          "cost": {
            "input": 0,
            "output": 0,
            "cacheRead": 0,
            "cacheWrite": 0
          },
          "context_window": 32768,
          "agentic": false,
          "available": false,
          "latency": 0.0,
          "error": "HTTP 404: {\"error\":{\"message\":\"model 'qwen2-vl:7b' not found\",\"type\":\"api_error\",\"param\":null,\"code\":null}}\n",
          "response_preview": null,
          "timestamp": "2026-02-24T22:34:15.584276"
        }
      ],
      "available": 1,
      "unavailable": 5
    },
    "nvidia-nim": {
      "name": "nvidia-nim",
      "models": [
        {
          "id": "z-ai/glm4.7",
          "name": "GLM-4.7 (NVIDIA NIM)",
          "provider": "nvidia-nim",
          "tier": "MEDIUM",
          "capabilities": [],
          "cost": {
            "input": 0.5,
            "output": 1.5,
            "cacheRead": 0,
            "cacheWrite": 0
          },
          "context_window": 131072,
          "agentic": false,
          "available": true,
          "latency": 1.047,
          "error": null,
          "response_preview": "Let me consider how to",
          "timestamp": "2026-02-24T22:34:16.631376"
        },
        {
          "id": "qwen/qwen2.5-7b-instruct",
          "name": "Qwen 2.5 7B (NIM)",
          "provider": "nvidia-nim",
          "tier": "SIMPLE",
          "capabilities": [],
          "cost": {
            "input": 0.15,
            "output": 0.6,
            "cacheRead": 0,
            "cacheWrite": 0
          },
          "context_window": 32768,
          "agentic": false,
          "available": true,
          "latency": 0.766,
          "error": null,
          "response_preview": "Hello! How can I",
          "timestamp": "2026-02-24T22:34:17.398112"
        },
        {
          "id": "meta/llama-3.1-70b-instruct",
          "name": "Llama 3.1 70B (NIM)",
          "provider": "nvidia-nim",
          "tier": "MEDIUM",
          "capabilities": [],
          "cost": {
            "input": 0.7,
            "output": 0.9,
            "cacheRead": 0,
            "cacheWrite": 0
          },
          "context_window": 128000,
          "agentic": false,
          "available": true,
          "latency": 0.502,
          "error": null,
          "response_preview": "How's it going?",
          "timestamp": "2026-02-24T22:34:17.901169"
        },
        {
          "id": "meta/llama-3.3-70b-instruct",
          "name": "Llama 3.3 70B (NIM)",
          "provider": "nvidia-nim",
          "tier": "MEDIUM",
          "capabilities": [],
          "cost": {
            "input": 0.4,
            "output": 0.4,
            "cacheRead": 0,
            "cacheWrite": 0
          },
          "context_window": 131072,
          "agentic": false,
          "available": true,
          "latency": 0.448,
          "error": null,
          "response_preview": "Hello! How can I",
          "timestamp": "2026-02-24T22:34:18.349511"
        },
        {
          "id": "deepseek-ai/deepseek-v3.2",
          "name": "DeepSeek V3.2 (NIM)",
          "provider": "nvidia-nim",
          "tier": "COMPLEX",
          "capabilities": [],
          "cost": {
            "input": 0.4,
            "output": 1.3,
            "cacheRead": 0,
            "cacheWrite": 0
          },
          "context_window": 131072,
          "agentic": false,
          "available": false,
          "latency": 30.255,
          "error": "The read operation timed out",
          "response_preview": null,
          "timestamp": "2026-02-24T22:34:48.604282"
        },
        {
          "id": "nvidia/llama-3.1-nemotron-ultra-253b-v1",
          "name": "Nemotron Ultra 253B (NIM)",
          "provider": "nvidia-nim",
          "tier": "COMPLEX",
          "capabilities": [],
          "cost": {
            "input": 2.5,
            "output": 5,
            "cacheRead": 0,
            "cacheWrite": 0
          },
          "context_window": 131072,
          "agentic": false,
          "available": true,
          "latency": 0.513,
          "error": null,
          "response_preview": "It seems like you might",
          "timestamp": "2026-02-24T22:34:49.118092"
        },
        {
          "id": "deepseek-ai/deepseek-r1-distill-qwen-32b",
          "name": "DeepSeek R1 Distill Qwen 32B (NIM)",
          "provider": "nvidia-nim",
          "tier": "REASONING",
          "capabilities": [],
          "cost": {
            "input": 0.6,
            "output": 1.5,
            "cacheRead": 0,
            "cacheWrite": 0
          },
          "context_window": 131072,
          "agentic": false,
          "available": false,
          "latency": 0.653,
          "error": "HTTP 500: {\"error\":\"Error during inference of request chat-339b026009774f8291abc678d25158f8 -- Encountered an error in forwardAsyn",
          "response_preview": null,
          "timestamp": "2026-02-24T22:34:49.770941"
        },
        {
          "id": "deepseek-ai/deepseek-r1-distill-qwen-14b",
          "name": "DeepSeek R1 Distill Qwen 14B (NIM)",
          "provider": "nvidia-nim",
          "tier": "REASONING",
          "capabilities": [],
          "cost": {
            "input": 0.3,
            "output": 1,
            "cacheRead": 0,
            "cacheWrite": 0
          },
          "context_window": 131072,
          "agentic": false,
          "available": true,
          "latency": 1.463,
          "error": null,
          "response_preview": "Hello",
          "timestamp": "2026-02-24T22:34:51.235359"
        },
        {
          "id": "qwen/qwq-32b",
          "name": "QwQ 32B (NIM)",
          "provider": "nvidia-nim",
          "tier": "REASONING",
          "capabilities": [],
          "cost": {
            "input": 0.6,
            "output": 1.5,
            "cacheRead": 0,
            "cacheWrite": 0
          },
          "context_window": 131072,
          "agentic": false,
          "available": true,
          "latency": 0.796,
          "error": null,
          "response_preview": "Okay, the user said",
          "timestamp": "2026-02-24T22:34:52.033396"
        },
        {
          "id": "qwen/qwen3-next-80b-a3b-thinking",
          "name": "Qwen3 Next 80B Thinking (NIM)",
          "provider": "nvidia-nim",
          "tier": "REASONING",
          "capabilities": [],
          "cost": {
            "input": 1.2,
            "output": 3,
            "cacheRead": 0,
            "cacheWrite": 0
          },
          "context_window": 131072,
          "agentic": false,
          "available": true,
          "latency": 0.667,
          "error": null,
          "response_preview": "Okay, the user said",
          "timestamp": "2026-02-24T22:34:52.702157"
        },
        {
          "id": "moonshotai/kimi-k2-thinking",
          "name": "Kimi K2 Thinking (NIM)",
          "provider": "nvidia-nim",
          "tier": "REASONING",
          "capabilities": [],
          "cost": {
            "input": 1,
            "output": 2.5,
            "cacheRead": 0,
            "cacheWrite": 0
          },
          "context_window": 131072,
          "agentic": false,
          "available": false,
          "latency": 30.25,
          "error": "The read operation timed out",
          "response_preview": null,
          "timestamp": "2026-02-24T22:35:22.953469"
        },
        {
          "id": "microsoft/phi-4-mini-flash-reasoning",
          "name": "Phi-4 Mini Flash Reasoning (NIM)",
          "provider": "nvidia-nim",
          "tier": "REASONING",
          "capabilities": [],
          "cost": {
            "input": 0.2,
            "output": 0.8,
            "cacheRead": 0,
            "cacheWrite": 0
          },
          "context_window": 128000,
          "agentic": false,
          "available": true,
          "latency": 0.71,
          "error": null,
          "response_preview": "(thinking model)",
          "timestamp": "2026-02-24T22:35:23.664892"
        },
        {
          "id": "meta/llama-4-maverick-17b-128e-instruct",
          "name": "Llama 4 Maverick 17B (NIM)",
          "provider": "nvidia-nim",
          "tier": "MEDIUM",
          "capabilities": [],
          "cost": {
            "input": 0.4,
            "output": 1,
            "cacheRead": 0,
            "cacheWrite": 0
          },
          "context_window": 131072,
          "agentic": false,
          "available": false,
          "latency": 30.265,
          "error": "The read operation timed out",
          "response_preview": null,
          "timestamp": "2026-02-24T22:35:53.931116"
        },
        {
          "id": "meta/llama-4-scout-17b-16e-instruct",
          "name": "Llama 4 Scout 17B (NIM)",
          "provider": "nvidia-nim",
          "tier": "MEDIUM",
          "capabilities": [],
          "cost": {
            "input": 0.4,
            "output": 1,
            "cacheRead": 0,
            "cacheWrite": 0
          },
          "context_window": 131072,
          "agentic": false,
          "available": false,
          "latency": 0.444,
          "error": "HTTP 404: {\"status\":404,\"title\":\"Not Found\",\"detail\":\"Function 'b6bb6e01-780e-4ba0-a5b8-379f00ed9b1c': Not found for account 'TTxq",
          "response_preview": null,
          "timestamp": "2026-02-24T22:35:54.375489"
        },
        {
          "id": "mistralai/mistral-large-3-675b-instruct-2512",
          "name": "Mistral Large 3 675B (NIM)",
          "provider": "nvidia-nim",
          "tier": "COMPLEX",
          "capabilities": [],
          "cost": {
            "input": 4.5,
            "output": 11,
            "cacheRead": 0,
            "cacheWrite": 0
          },
          "context_window": 131072,
          "agentic": false,
          "available": true,
          "latency": 0.931,
          "error": null,
          "response_preview": "Hello! \ud83d\ude0a",
          "timestamp": "2026-02-24T22:35:55.306384"
        },
        {
          "id": "nvidia/llama-3.3-nemotron-super-49b-v1.5",
          "name": "Nemotron Super 49B v1.5 (NIM)",
          "provider": "nvidia-nim",
          "tier": "MEDIUM",
          "capabilities": [],
          "cost": {
            "input": 1.8,
            "output": 3.5,
            "cacheRead": 0,
            "cacheWrite": 0
          },
          "context_window": 131072,
          "agentic": false,
          "available": true,
          "latency": 0.462,
          "error": null,
          "response_preview": "(thinking model)",
          "timestamp": "2026-02-24T22:35:55.768405"
        },
        {
          "id": "nvidia/llama-3.1-nemotron-51b-instruct",
          "name": "Nemotron 51B (NIM)",
          "provider": "nvidia-nim",
          "tier": "MEDIUM",
          "capabilities": [],
          "cost": {
            "input": 1.8,
            "output": 3.5,
            "cacheRead": 0,
            "cacheWrite": 0
          },
          "context_window": 131072,
          "agentic": false,
          "available": false,
          "latency": 0.418,
          "error": "HTTP 404: {\"status\":404,\"title\":\"Not Found\",\"detail\":\"Function '5beba52c-65a9-4f46-8cd9-656689a1b205': Not found for account 'TTxq",
          "response_preview": null,
          "timestamp": "2026-02-24T22:35:56.186348"
        },
        {
          "id": "meta/llama-3.2-11b-vision-instruct",
          "name": "NIM Vision Model 1",
          "provider": "nvidia-nim",
          "tier": "MEDIUM",
          "capabilities": [],
          "cost": {
            "input": 0.2,
            "output": 0.8,
            "cacheRead": 0,
            "cacheWrite": 0
          },
          "context_window": 128000,
          "agentic": false,
          "available": true,
          "latency": 0.723,
          "error": null,
          "response_preview": "How can I assist you",
          "timestamp": "2026-02-24T22:35:56.910661"
        },
        {
          "id": "microsoft/phi-3.5-vision-instruct",
          "name": "NIM Vision Model 2",
          "provider": "nvidia-nim",
          "tier": "SIMPLE",
          "capabilities": [],
          "cost": {
            "input": 0.15,
            "output": 0.6,
            "cacheRead": 0,
            "cacheWrite": 0
          },
          "context_window": 128000,
          "agentic": false,
          "available": true,
          "latency": 0.724,
          "error": null,
          "response_preview": "This instruction is",
          "timestamp": "2026-02-24T22:35:57.636484"
        },
        {
          "id": "z-ai/glm5",
          "name": "GLM-5 744B MoE",
          "provider": "nvidia-nim",
          "tier": "COMPLEX",
          "capabilities": [],
          "cost": {},
          "context_window": 131072,
          "agentic": false,
          "available": true,
          "latency": 3.809,
          "error": null,
          "response_preview": "Let me consider how to",
          "timestamp": "2026-02-24T22:36:01.447212"
        },
        {
          "id": "minimaxai/minimax-m2.1",
          "name": "MiniMax M2.1 456B",
          "provider": "nvidia-nim",
          "tier": "COMPLEX",
          "capabilities": [],
          "cost": {},
          "context_window": 1000000,
          "agentic": false,
          "available": true,
          "latency": 12.521,
          "error": null,
          "response_preview": "(thinking model)",
          "timestamp": "2026-02-24T22:36:13.969743"
        },
        {
          "id": "minimaxai/minimax-m2",
          "name": "MiniMax M2 456B",
          "provider": "nvidia-nim",
          "tier": "COMPLEX",
          "capabilities": [],
          "cost": {},
          "context_window": 1000000,
          "agentic": false,
          "available": true,
          "latency": 0.677,
          "error": null,
          "response_preview": "(thinking model)",
          "timestamp": "2026-02-24T22:36:14.648550"
        }
      ],
      "available": 16,
      "unavailable": 6
    },
    "anthropic-proxy-1": {
      "name": "anthropic-proxy-1",
      "models": [
        {
          "id": "claude-opus-4-6",
          "name": "Claude Opus 4.6 (Proxy 1)",
          "provider": "anthropic-proxy-1",
          "tier": "CRITICAL",
          "capabilities": [],
          "cost": {
            "input": 5,
            "output": 25,
            "cacheRead": 0.5,
            "cacheWrite": 6.25
          },
          "context_window": 1000000,
          "agentic": false,
          "available": true,
          "latency": 0.0,
          "error": null,
          "response_preview": "(OAuth \u2014 tested via OpenClaw, not raw HTTP)",
          "timestamp": "2026-02-24T22:36:14.649713"
        },
        {
          "id": "claude-sonnet-4-6",
          "name": "Claude Sonnet 4.6 (Proxy 1)",
          "provider": "anthropic-proxy-1",
          "tier": "COMPLEX",
          "capabilities": [],
          "cost": {
            "input": 3,
            "output": 15,
            "cacheRead": 0.3,
            "cacheWrite": 3.75
          },
          "context_window": 200000,
          "agentic": false,
          "available": true,
          "latency": 0.0,
          "error": null,
          "response_preview": "(OAuth \u2014 tested via OpenClaw, not raw HTTP)",
          "timestamp": "2026-02-24T22:36:14.650652"
        }
      ],
      "available": 2,
      "unavailable": 0
    },
    "anthropic-proxy-2": {
      "name": "anthropic-proxy-2",
      "models": [
        {
          "id": "claude-sonnet-4-5",
          "name": "Claude Sonnet (Proxy 2)",
          "provider": "anthropic-proxy-2",
          "tier": "COMPLEX",
          "capabilities": [],
          "cost": {
            "input": 3,
            "output": 15,
            "cacheRead": 0,
            "cacheWrite": 0
          },
          "context_window": 200000,
          "agentic": false,
          "available": false,
          "latency": 0.958,
          "error": "HTTP 400: {\"request_id\":\"771932975414116411\",\"ResponseMeta\":{\"RequestId\":\"771932975414116411\",\"ErrorCode\":\"InvalidArgument\",\"Error",
          "response_preview": null,
          "timestamp": "2026-02-24T22:36:15.610051"
        },
        {
          "id": "claude-opus-4-5",
          "name": "Claude Opus (Proxy 2)",
          "provider": "anthropic-proxy-2",
          "tier": "CRITICAL",
          "capabilities": [],
          "cost": {
            "input": 15,
            "output": 75,
            "cacheRead": 0,
            "cacheWrite": 0
          },
          "context_window": 200000,
          "agentic": false,
          "available": false,
          "latency": 0.428,
          "error": "HTTP 400: {\"request_id\":\"771932975842116411\",\"ResponseMeta\":{\"RequestId\":\"771932975842116411\",\"ErrorCode\":\"InvalidArgument\",\"Error",
          "response_preview": null,
          "timestamp": "2026-02-24T22:36:16.038791"
        }
      ],
      "available": 0,
      "unavailable": 2
    },
    "anthropic-proxy-4": {
      "name": "anthropic-proxy-4",
      "models": [
        {
          "id": "glm-4.7",
          "name": "GLM 4.7 (z.ai Key 2)",
          "provider": "anthropic-proxy-4",
          "tier": "MEDIUM",
          "capabilities": [],
          "cost": {
            "input": 0.5,
            "output": 1.5,
            "cacheRead": 0,
            "cacheWrite": 0
          },
          "context_window": 131072,
          "agentic": false,
          "available": true,
          "latency": 2.056,
          "error": null,
          "response_preview": "Hi there! I'm the GLM language model tra",
          "timestamp": "2026-02-24T22:36:18.096497"
        }
      ],
      "available": 1,
      "unavailable": 0
    },
    "anthropic-proxy-5": {
      "name": "anthropic-proxy-5",
      "models": [
        {
          "id": "deepseek-chat",
          "name": "Provider 5 Model",
          "provider": "anthropic-proxy-5",
          "tier": "COMPLEX",
          "capabilities": [],
          "cost": {
            "input": 3,
            "output": 15,
            "cacheRead": 0,
            "cacheWrite": 0
          },
          "context_window": 200000,
          "agentic": false,
          "available": true,
          "latency": 0.307,
          "error": null,
          "response_preview": "\u4f60\u597d\uff01\ud83d\udc4b ",
          "timestamp": "2026-02-24T22:36:19.726729"
        }
      ],
      "available": 1,
      "unavailable": 0
    },
    "anthropic": {
      "name": "anthropic",
      "models": [
        {
          "id": "claude-opus-4-6",
          "name": "Claude Opus 4.6 (OAuth)",
          "provider": "anthropic",
          "tier": "CRITICAL",
          "capabilities": [],
          "cost": {
            "input": 5,
            "output": 25,
            "cacheRead": 0.5,
            "cacheWrite": 6.25
          },
          "context_window": 1000000,
          "agentic": false,
          "available": true,
          "latency": 0.0,
          "error": null,
          "response_preview": "(OAuth \u2014 tested via OpenClaw, not raw HTTP)",
          "timestamp": "2026-02-24T22:36:19.727943"
        },
        {
          "id": "claude-sonnet-4-5",
          "name": "Claude Sonnet 4.5 (OAuth)",
          "provider": "anthropic",
          "tier": "COMPLEX",
          "capabilities": [],
          "cost": {
            "input": 3,
            "output": 15,
            "cacheRead": 0.3,
            "cacheWrite": 3.75
          },
          "context_window": 200000,
          "agentic": false,
          "available": true,
          "latency": 0.0,
          "error": null,
          "response_preview": "(OAuth \u2014 tested via OpenClaw, not raw HTTP)",
          "timestamp": "2026-02-24T22:36:19.728867"
        },
        {
          "id": "claude-opus-4-5",
          "name": "Claude Opus 4.5 (OAuth)",
          "provider": "anthropic",
          "tier": "CRITICAL",
          "capabilities": [],
          "cost": {
            "input": 15,
            "output": 75,
            "cacheRead": 1.5,
            "cacheWrite": 18.75
          },
          "context_window": 200000,
          "agentic": false,
          "available": true,
          "latency": 0.0,
          "error": null,
          "response_preview": "(OAuth \u2014 tested via OpenClaw, not raw HTTP)",
          "timestamp": "2026-02-24T22:36:19.729788"
        },
        {
          "id": "claude-sonnet-4-6",
          "name": "Claude Sonnet 4.6 (OAuth)",
          "provider": "anthropic",
          "tier": "COMPLEX",
          "capabilities": [],
          "cost": {
            "input": 3,
            "output": 15,
            "cacheRead": 0.3,
            "cacheWrite": 3.75
          },
          "context_window": 200000,
          "agentic": false,
          "available": true,
          "latency": 0.0,
          "error": null,
          "response_preview": "(OAuth \u2014 tested via OpenClaw, not raw HTTP)",
          "timestamp": "2026-02-24T22:36:19.730699"
        }
      ],
      "available": 4,
      "unavailable": 0
    },
    "anthropic-proxy-6": {
      "name": "anthropic-proxy-6",
      "models": [
        {
          "id": "glm-4.7",
          "name": "GLM 4.7 (z.ai Key 1)",
          "provider": "anthropic-proxy-6",
          "tier": "MEDIUM",
          "capabilities": [],
          "cost": {
            "input": 0.5,
            "output": 1.5,
            "cacheRead": 0,
            "cacheWrite": 0
          },
          "context_window": 131072,
          "agentic": false,
          "available": true,
          "latency": 18.889,
          "error": null,
          "response_preview": "Hi there! I'm the GLM language model tra",
          "timestamp": "2026-02-24T22:36:38.620987"
        }
      ],
      "available": 1,
      "unavailable": 0
    },
    "ollama-gpu-server": {
      "name": "ollama-gpu-server",
      "models": [
        {
          "id": "glm-4.7-flash",
          "name": "GLM-4.7-flash (GPU Server Local)",
          "provider": "ollama-gpu-server",
          "tier": "SIMPLE",
          "capabilities": [],
          "cost": {
            "input": 0,
            "output": 0,
            "cacheRead": 0,
            "cacheWrite": 0
          },
          "context_window": 32768,
          "agentic": false,
          "available": false,
          "latency": 0.004,
          "error": "<urlopen error [Errno 111] Connection refused>",
          "response_preview": null,
          "timestamp": "2026-02-24T22:36:38.626281"
        }
      ],
      "available": 0,
      "unavailable": 1
    }
  }
}