---
name: surrealdb-memory
description: "A comprehensive knowledge graph memory system with semantic search, episodic memory, working memory, automatic context injection, and per-agent isolation."
version: 2.2.2
metadata:
  openclaw:
    requires:
      env:
        - OPENAI_API_KEY
        - SURREAL_USER
        - SURREAL_PASS
        - SURREAL_URL
      bins:
        - surreal
        - python3
    primaryEnv: OPENAI_API_KEY
    emoji: "ğŸ§ "
    homepage: "https://clawhub.com/skills/surrealdb-knowledge-graph-memory"
---

# SurrealDB Knowledge Graph Memory v2.2

A comprehensive knowledge graph memory system with semantic search, episodic memory, working memory, automatic context injection, and **per-agent isolation** â€” enabling every agent to become a continuously self-improving AI.

## Description

Use this skill for:
- **Semantic Memory** â€” Store and retrieve facts with confidence-weighted vector search
- **Episodic Memory** â€” Record task histories and learn from past experiences
- **Working Memory** â€” Track active task state with crash recovery
- **Auto-Injection** â€” Automatically inject relevant context into agent prompts
- **Outcome Calibration** â€” Facts gain/lose confidence based on task outcomes
- **Self-Improvement** â€” Scheduled extraction and relation discovery make every agent smarter over time

**Triggers:** "remember this", "store fact", "what do you know about", "memory search", "find similar tasks", "learn from history"

> **Security:** This skill reads workspace memory files and sends their content to OpenAI for extraction. It registers two background cron jobs and (optionally) patches OpenClaw source files. All behaviors are opt-in or documented. See [SECURITY.md](SECURITY.md) for the full breakdown before enabling.
>
> **Required:** `OPENAI_API_KEY`, `surreal` binary, `python3` â‰¥3.10

---

## ğŸ”„ Self-Improving Agent Loop

This is the core concept: **every agent equipped with this skill improves itself automatically**, with no manual intervention required. Two scheduled cron jobs â€” knowledge extraction and relationship correlation â€” run on a fixed schedule and continuously grow the knowledge graph. Combined with auto-injection, the agent gets progressively smarter with each conversation.

### The Cycle

```
[Agent Conversation]
       â†“  stores important facts via knowledge_store_sync
[Memory Files]  â† agent writes to MEMORY.md / daily memory/*.md files
       â†“  every 6 hours â€” extraction cron fires
[Entity + Fact Extraction]  â† LLM reads files, extracts structured facts + entities
       â†“  facts stored with embeddings + agent_id tag
[Knowledge Graph]  â† SurrealDB: facts, entities, mentions
       â†“  daily at 3 AM â€” relation discovery cron fires
[Relationship Correlation]  â† AI finds semantic links between facts
       â†“  relates_to edges created between connected facts
[Richer Knowledge Graph]  â† facts are no longer isolated; they form a web
       â†“  on every new message â€” auto-injection reads the graph
[Context Window]  â† relevant facts + relations + episodes injected automatically
       â†“
[Better Responses]  â† agent uses accumulated knowledge to respond more accurately
       â†‘  new insights written back to memory files â†’ cycle repeats
```

### What Each Scheduled Job Does

#### Job 1 â€” Knowledge Extraction (every 6 hours)
**Script:** `scripts/extract-knowledge.py extract`

- Reads `MEMORY.md` and all `memory/YYYY-MM-DD.md` files in the workspace
- Uses an LLM (GPT-4) to extract structured facts, entities, and key concepts
- Hashes file content to skip unchanged files â€” only processes diffs
- Stores each fact with:
  - A vector embedding (OpenAI `text-embedding-3-small`) for semantic search
  - A `confidence` score (defaults to 0.9)
  - An `agent_id` tag so facts stay isolated to the right agent
  - `source` metadata pointing back to the originating file
- Result: raw conversational knowledge becomes searchable, structured memory

#### Job 2 â€” Relationship Correlation (daily at 3 AM)
**Script:** `scripts/extract-knowledge.py discover-relations`

- Queries the graph for facts that have no relationships yet ("isolated facts")
- Batches them and asks an LLM to identify semantic connections between them
- Creates `relates_to` edges in SurrealDB linking related facts
- Result: isolated facts become a **connected knowledge web** â€” the agent can now traverse relationships, not just keyword-match
- Over time, the graph evolves from a flat list into a rich semantic network

### Why This Makes Agents Self-Improving

When auto-injection is enabled, every new conversation starts with the most relevant slice of the accumulated knowledge graph. As the agent:
1. Has conversations â†’ writes insights to memory files
2. Extraction job fires â†’ converts those insights into structured facts
3. Relation job fires â†’ connects those facts to existing knowledge
4. Next conversation â†’ auto-injection pulls in richer, more connected context

...the agent effectively gets smarter with every cycle. It learns from its own outputs, grounds future responses in its accumulated history, and avoids repeating mistakes (via episodic memory and outcome calibration).

### OpenClaw Cron Jobs (as configured)

These jobs are registered in OpenClaw and run automatically:

| Job Name | Cron ID | Schedule | What it runs |
|----------|---------|----------|--------------|
| Memory Knowledge Extraction | `b9936b69-c652-4683-9eae-876cd02128c7` | Every 6 hours (`0 */6 * * *`) | `python3 scripts/extract-knowledge.py extract` |
| Memory Relation Discovery | `2a3dd973-5d4d-46cf-848d-0cf31ab53fa1` | Daily at 3 AM (`0 3 * * *`) | `python3 scripts/extract-knowledge.py discover-relations` |

> **Updated 2026-02-26:** Both jobs now use `sessionTarget: "isolated"` with `agentTurn` payload and `delivery: none`. They run in fully isolated background sessions and **never fire into the main agent session** â€” no main-session context is consumed and your active chat is not affected. A bottom-right corner toast notification appears in the Control UI when each job starts and completes (auto-dismisses after 4 seconds).

To check job status at any time:
```bash
# Via OpenClaw cron list (in Koda's chat)
# Or via CLI:
openclaw cron list
```

### Adding Cron Jobs for a New Agent

When spawning a new agent that should self-improve, register its own extraction job:

```bash
# OpenClaw cron add (via Koda) â€” example for a 'scout-monitor' agent
# Schedule: every 6h, extract facts tagged to scout-monitor
python3 scripts/extract-knowledge.py extract --agent-id scout-monitor
```

The `--agent-id` flag ensures extracted facts are isolated to that agent's pool and don't pollute the main agent's knowledge. Each agent self-improves independently while still reading shared `scope='global'` facts.

---

## Features (v2.2)

| Feature | Description |
|---------|-------------|
| **Semantic Facts** | Vector-indexed facts with confidence scoring |
| **Episodic Memory** | Task histories with decisions, problems, solutions, learnings |
| **Working Memory** | YAML-based task state that survives crashes |
| **Outcome Calibration** | Facts used in successful tasks gain confidence |
| **Auto-Injection** | Relevant facts/episodes injected into prompts automatically |
| **Entity Extraction** | Automatic entity linking and relationship discovery |
| **Confidence Decay** | Stale facts naturally decay over time |
| **Agent Isolation** | Each agent has its own scoped memory pool; `scope='global'` facts are shared across all agents |
| **Self-Improving Loop** | Scheduled extraction + relation discovery automatically grow the graph |

---

## Agent Isolation (v2.2)

Each agent in OpenClaw has its own scoped memory pool. Facts are tagged with `agent_id` on write; all read queries filter to `(agent_id = $agent_id OR scope = 'global')`.

### How it works

```
Agent A (main)          Agent B (scout-monitor)
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ 391 factsâ”‚              â”‚   0 factsâ”‚   â† isolated pools
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†‘                         â†‘
         â””â”€â”€â”€â”€ scope='global' â”€â”€â”€â”€â”€â”˜   â† shared facts visible to both
```

### Storing facts

All `knowledge_store` / `knowledge_store_sync` calls accept `agent_id`:

```bash
# Stored to scout-monitor's pool only
mcporter call surrealdb-memory.knowledge_store \
    content="API is healthy at /ping" \
    agent_id='scout-monitor'

# Stored globally (visible to all agents)
mcporter call surrealdb-memory.knowledge_store \
    content="Project uses Python 3.12" \
    agent_id='main' scope='global'
```

### Auto-injection (agent-aware)

With `references/enhanced-loop-hook-agent-isolation.md` applied to `src/agents/enhanced-loop-hook.ts`, the enhanced loop automatically extracts the agent ID from the session key and passes it to `memory_inject`. No manual configuration needed â€” each agent's auto-injection is silently scoped to its own facts.

### Extraction (agent-aware)

Pass `--agent-id` to `extract-knowledge.py` so cron-extracted facts are correctly tagged:

```bash
python3 scripts/extract-knowledge.py extract --agent-id scout-monitor
```

Default is `"main"`. Update cron jobs accordingly for non-main agents.

### Backward compatibility

Existing facts without an explicit `agent_id` are treated as owned by `"main"`. Nothing is lost on upgrade to v2.2.

---

## Dashboard UI

The Memory tab in the Control dashboard provides a two-column layout:

### Left Column: Dashboard
- **ğŸ“Š Statistics** â€” Live counts of facts, entities, relations, and archived items
- **Confidence Bar** â€” Visual display of average confidence score
- **Sources Breakdown** â€” Facts grouped by source file
- **ğŸ¥ System Health** â€” Status of SurrealDB, schema, and Python dependencies
- **ğŸ”— DB Studio** â€” Quick link to SurrealDB's web interface

### Right Column: Operations
- **ğŸ“¥ Knowledge Extraction**
  - *Extract Changes* â€” Incrementally extract facts from modified files
  - *Find Relations* â€” Discover semantic relationships between existing facts
  - *Full Sync* â€” Complete extraction + relation discovery
  - Progress bar with real-time status updates
  
- **ğŸ”§ Maintenance**
  - *Apply Decay* â€” Reduce confidence of stale facts
  - *Prune Stale* â€” Archive facts below threshold
  - *Full Sweep* â€” Complete maintenance cycle

- **ğŸ’¡ Tips** â€” Quick reference for operations

When the system needs setup, an **Installation** section appears with manual controls.

---

## Prerequisites

1. **SurrealDB** installed and running:
   ```bash
   # Install (one-time)
   ./scripts/install.sh
   
   # Start server
   surreal start --bind 127.0.0.1:8000 --user root --pass root file:~/.openclaw/memory/knowledge.db
   ```

2. **Python dependencies** (use the skill's venv):
   ```bash
   cd /path/to/surrealdb-memory
   python3 -m venv .venv
   source .venv/bin/activate
   pip install surrealdb openai pyyaml
   ```

3. **OpenAI API key** for embeddings (set in OpenClaw config or environment)

4. **mcporter** configured with this skill's MCP server

## MCP Server Setup

Add to your `config/mcporter.json`:

```json
{
  "servers": {
    "surrealdb-memory": {
      "command": ["python3", "/path/to/surrealdb-memory/scripts/mcp-server-v2.py"],
      "env": {
        "OPENAI_API_KEY": "${OPENAI_API_KEY}",
        "SURREAL_URL": "http://localhost:8000",
        "SURREAL_USER": "root",
        "SURREAL_PASS": "root"
      }
    }
  }
}
```

---

## MCP Tools (11 total)

### Core Tools
| Tool | Description |
|------|-------------|
| `knowledge_search` | Semantic search for facts |
| `knowledge_recall` | Get a fact with full context (relations, entities) |
| `knowledge_store` | Store a new fact |
| `knowledge_stats` | Get database statistics |

### v2 Tools
| Tool | Description |
|------|-------------|
| `knowledge_store_sync` | Store with importance routing (high importance = immediate write) |
| `episode_search` | Find similar past tasks |
| `episode_learnings` | Get actionable learnings from history |
| `episode_store` | Record a completed task episode |
| `working_memory_status` | Get current task state |
| `context_aware_search` | Search with task context boosting |
| `memory_inject` | **Intelligent context injection for prompts** |

### memory_inject Tool

The `memory_inject` tool returns formatted context ready for prompt injection:

```bash
# Scoped to a specific agent (returns only that agent's facts + global facts)
mcporter call surrealdb-memory.memory_inject \
    query="user message" \
    max_facts:7 \
    max_episodes:3 \
    confidence_threshold:0.9 \
    include_relations:true \
    agent_id='scout-monitor'
```

**Output:**
```markdown
## Semantic Memory (Relevant Facts)
ğŸ“Œ [60% relevant, 100% confidence] Relevant fact here...

## Related Entities
â€¢ Entity Name (type)

## Episodic Memory (Past Experiences)
âœ… Task: Previous task goal [similarity]
   â†’ Key learning from that task
```

---

## Auto-Injection (Enhanced Loop Integration)

When enabled, memory is automatically injected into every agent turn:

1. **Enable in Mode UI:**
   - Open Control dashboard â†’ Mode tab
   - Scroll to "ğŸ§  Memory & Knowledge Graph" section
   - Toggle "Auto-Inject Context"
   - Configure limits (max facts, max episodes, confidence threshold)

2. **How it works:**
   - On each user message, `memory_inject` is called automatically
   - Relevant facts are searched based on the user's query
   - If average fact confidence < threshold, episodic memories are included
   - Formatted context is injected into the agent's system prompt
   - **v2.2:** With `references/enhanced-loop-hook-agent-isolation.md` applied, the active agent's ID is automatically extracted from the session key and passed as `agent_id` â€” each agent's injection is silently scoped to its own facts

3. **Configuration (in Mode settings):**
   | Setting | Default | Description |
   |---------|---------|-------------|
   | Auto-Inject Context | Off | Master toggle |
   | Max Facts | 7 | Maximum semantic facts to inject |
   | Max Episodes | 3 | Maximum episodic memories |
   | Confidence Threshold | 90% | Include episodes when below this |
   | Include Relations | On | Include entity relationships |

---

## CLI Commands

```bash
# Activate venv
source .venv/bin/activate

# Store a fact
python scripts/memory-cli.py store "Important fact" --confidence 0.9

# Search
python scripts/memory-cli.py search "query"

# Get stats
python scripts/knowledge-tool.py stats

# Run maintenance
python scripts/memory-cli.py maintain

# Extract from files (incremental)
python scripts/extract-knowledge.py extract

# Extract for a specific agent
python scripts/extract-knowledge.py extract --agent-id scout-monitor

# Force full extraction (all files, not just changed)
python scripts/extract-knowledge.py extract --full

# Discover semantic relationships
python scripts/extract-knowledge.py discover-relations
```

---

## Database Schema (v2)

### Tables
- `fact` â€” Semantic facts with embeddings and confidence
- `entity` â€” Extracted entities (people, places, concepts)
- `relates_to` â€” Relationships between facts
- `mentions` â€” Fact-to-entity links
- `episode` â€” Task histories with outcomes
- `working_memory` â€” Active task snapshots

### Key Fields (fact)
- `content` â€” The fact text
- `embedding` â€” Vector for semantic search
- `confidence` â€” Base confidence (0-1)
- `success_count` / `failure_count` â€” Outcome tracking
- `scope` â€” global, client, or agent
- `agent_id` â€” Which agent owns this fact (v2.2)

### Key Fields (episode)
- `goal` â€” What was attempted
- `outcome` â€” success, failure, abandoned
- `decisions` â€” Key decisions made
- `problems` â€” Problems encountered (structured)
- `solutions` â€” Solutions applied (structured)
- `key_learnings` â€” Extracted lessons

---

## Confidence Scoring

Effective confidence is calculated from:
- **Base confidence** (0.0â€“1.0)
- **+ Inherited boost** from supporting facts
- **+ Entity boost** from well-established entities
- **+ Outcome adjustment** based on success/failure history
- **- Contradiction drain** from conflicting facts
- **- Time decay** (configurable, ~5% per month)

---

## Maintenance

### Automated â€” OpenClaw Cron (as deployed)

The self-improving loop runs via two registered OpenClaw cron jobs:

```
Every 6h  â†’ python3 scripts/extract-knowledge.py extract
             (reads memory files, extracts facts into the graph)

Daily 3AM â†’ python3 scripts/extract-knowledge.py discover-relations
             (finds semantic relationships between existing facts)
```

These jobs are pre-registered in OpenClaw. To verify they're active:
```bash
openclaw cron list
# or ask Koda: "list cron jobs"
```

To manually trigger extraction:
```bash
# From the Memory dashboard UI: click "Extract Changes" or "Find Relations"
# Or via CLI:
cd ~/openclaw/skills/surrealdb-memory && source .venv/bin/activate
python3 scripts/extract-knowledge.py extract
python3 scripts/extract-knowledge.py discover-relations
```

### Manual (UI)
Use the **Maintenance** section in the Memory tab:
- **Apply Decay** â€” Reduce confidence of stale facts
- **Prune Stale** â€” Archive facts below 0.3 confidence
- **Full Sweep** â€” Run complete maintenance cycle

---

## Files

### Scripts
| File | Purpose |
|------|---------|
| `mcp-server-v2.py` | MCP server with all 11 tools |
| `mcp-server.py` | Legacy v1 MCP server |
| `episodes.py` | Episodic memory module |
| `working_memory.py` | Working memory module |
| `memory-cli.py` | CLI for manual operations |
| `extract-knowledge.py` | Bulk extraction from files (supports `--agent-id`) |
| `knowledge-tools.py` | Higher-level extraction |
| `schema-v2.sql` | v2 database schema |
| `migrate-v2.py` | Migration script |

### Integration
| File | Purpose |
|------|---------|
| `openclaw-integration/gateway/memory.ts` | Gateway server methods |
| `openclaw-integration/ui/memory-view.ts` | Memory dashboard UI |
| `openclaw-integration/ui/memory-controller.ts` | UI controller |

---

## Troubleshooting

**"Connection refused"**
â†’ Start SurrealDB: `surreal start --bind 127.0.0.1:8000 --user root --pass root file:~/.openclaw/memory/knowledge.db`

**"No MCP servers configured"**
â†’ Ensure mcporter is run from a directory containing `config/mcporter.json` with the surrealdb-memory server defined

**Memory injection returning null**
â†’ Check that `OPENAI_API_KEY` is set in the environment
â†’ Verify SurrealDB is running and schema is initialized

**Empty search results**
â†’ Run extraction from the UI or via CLI: `python3 scripts/extract-knowledge.py extract`

**"No facts to analyze" on relation discovery**
â†’ This is normal if all facts are already related â€” the graph is well-connected. Run extraction first if the graph is empty.

**Progress bar not updating**
â†’ Ensure the gateway has been restarted after UI updates
â†’ Check browser console for polling errors

**Facts from wrong agent appearing**
â†’ Check that `agent_id` is being passed correctly to all store/search calls
â†’ Verify `references/enhanced-loop-hook-agent-isolation.md` is applied for auto-injection scoping

---

## Migration from v1 / v2.1

```bash
# Apply v2 schema (additive, won't delete existing data)
./scripts/migrate-v2.sh

# Or manually:
source .venv/bin/activate
python scripts/migrate-v2.py
```

All existing facts without an `agent_id` are treated as owned by `"main"` â€” backward compatible.

---

## Stats

Check your knowledge graph via UI (Dashboard section) or CLI:
```bash
mcporter call surrealdb-memory.knowledge_stats
```

Example output:
```json
{
  "facts": 379,
  "entities": 485,
  "relations": 106,
  "episodes": 3,
  "avg_confidence": 0.99
}
```

---

*v2.2 â€” Agent isolation, self-improving loop, cron-based extraction & relationship correlation*
