#!/usr/bin/env python3
"""
Semantic Router - å¯é…ç½®çš„è¯­ä¹‰æ£€æŸ¥ä¸æ¨¡å‹è·¯ç”±è„šæœ¬
æ”¯æŒä»é…ç½®æ–‡ä»¶è¯»å–æ¨¡å‹æ± å’Œä»»åŠ¡ç±»å‹
æ”¯æŒè‡ªåŠ¨æ¨¡å‹åˆ‡æ¢ (--execute / -e)
"""

import json
import sys
import os
import subprocess
import argparse
from datetime import datetime

# è·å–æŠ€èƒ½ç›®å½•
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
CONFIG_DIR = os.path.join(os.path.dirname(SCRIPT_DIR), 'config')

# é»˜è®¤é…ç½®ç›®å½•ï¼ˆå…¼å®¹ç›´æ¥è¿è¡Œï¼‰
if not os.path.exists(CONFIG_DIR):
    CONFIG_DIR = os.path.expanduser('~/.openclaw/workspace/.lib')

def load_json(filename, default=None):
    """åŠ è½½ JSON é…ç½®æ–‡ä»¶"""
    path = os.path.join(CONFIG_DIR, filename)
    try:
        if os.path.exists(path):
            with open(path, 'r', encoding='utf-8') as f:
                return json.load(f)
    except Exception as e:
        print(f"Warning: Failed to load {filename}: {e}", file=sys.stderr)
    return default or {}

# åŠ è½½é…ç½®
MODEL_POOLS = load_json('pools.json', {})
TASK_PATTERNS = load_json('tasks.json', {})

# å¤‡ç”¨ç¡¬ç¼–ç ï¼ˆé…ç½®æ–‡ä»¶ä¸å­˜åœ¨æ—¶ï¼‰
if not MODEL_POOLS:
    MODEL_POOLS = {
        "Intelligence": {"name": "æ™ºèƒ½æ± ", "primary": "openai-codex/gpt-5.3-codex", "fallback_1": "kimi-k2.5", "fallback_2": "minimax-cn/MiniMax-M2.5"},
        "Highspeed": {"name": "é«˜é€Ÿæ± ", "primary": "openai/gpt-4o-mini", "fallback_1": "glm-4.7-flashx", "fallback_2": "minimax-cn/MiniMax-M2.5"},
        "Humanities": {"name": "äººæ–‡æ± ", "primary": "openai/gpt-4o", "fallback_1": "kimi-k2.5", "fallback_2": "minimax-cn/MiniMax-M2.5"}
    }

if not TASK_PATTERNS:
    TASK_PATTERNS = {
        "continue": {"keywords": ["ç»§ç»­", "æ¥ç€"], "pool": None, "action": "å»¶ç»­"},
        "development": {"keywords": ["å¼€å‘", "å†™ä»£ç "], "pool": "Intelligence", "action": "æ‰§è¡Œå¼€å‘ä»»åŠ¡"},
    }

# æŒ‡ç¤ºè¯é…ç½®
CONTINUATION_INDICATORS = {
    "pronouns": ["è¿™ä¸ª", "é‚£ä¸ª", "å®ƒ", "è¿™", "é‚£"],
    "supplements": ["è¿˜æœ‰", "å¦å¤–", "ç»§ç»­", "è¡¥å……"],
    "confirmations": ["å¯¹çš„", "æ˜¯çš„", "å¥½çš„"]
}

def keyword_match(user_input: str):
    """å…³é”®è¯åŒ¹é…"""
    text = user_input.lower().strip()
    
    for task_type, config in TASK_PATTERNS.items():
        is_standalone = config.get("standalone", False)
        
        for kw in config.get("keywords", []):
            if is_standalone:
                if text == kw or text.startswith(kw + " ") or text.startswith(kw + "?"):
                    return task_type, config.get("action"), config.get("pool"), task_type == "continue"
            else:
                if kw in text:
                    return task_type, config.get("action"), config.get("pool"), task_type == "continue"
    
    return None, None, None, False

def indicator_match(user_input: str) -> bool:
    """æŒ‡ç¤ºè¯æ£€æµ‹"""
    text = user_input.lower().strip()
    for indicators in CONTINUATION_INDICATORS.values():
        for indicator in indicators:
            if indicator in text:
                return True
    return False

def jaccard_similarity(text1: str, text2: str) -> float:
    """Jaccard ç›¸ä¼¼åº¦"""
    import re
    tokens1 = set(re.findall(r'[\u4e00-\u9fff]+|[a-zA-Z]+', text1.lower()))
    tokens2 = set(re.findall(r'[\u4e00-\u9fff]+|[a-zA-Z]+', text2.lower()))
    if not tokens1 or not tokens2:
        return 0.0
    intersection = len(tokens1 & tokens2)
    union = len(tokens1 | tokens2)
    return intersection / union if union > 0 else 0.0

def embedding_similarity_check(user_input: str, context_messages: list, threshold: float = 0.1) -> tuple:
    """è¯æ±‡é‡å åº¦æ£€æµ‹"""
    if not context_messages:
        return False, 0.0, "no_context"
    
    context_text = " ".join(context_messages)
    score = jaccard_similarity(user_input, context_text)
    return score >= threshold, score, "embedding_jaccard"

def detect_task_type(user_input: str, context_messages: list = None):
    """æ£€æµ‹ä»»åŠ¡ç±»å‹"""
    # Step 1: å…³é”®è¯åŒ¹é…
    task_type, action, pool, is_continue = keyword_match(user_input)
    
    if task_type:
        branch = "B" if is_continue else "C"
        detection = "keyword_continue" if is_continue else "keyword"
        return task_type, action, pool, branch, detection
    
    # Step 2: æŒ‡ç¤ºè¯
    if indicator_match(user_input):
        return "continue", "å»¶ç»­", None, "B", "indicator"
    
    # Step 3: ç›¸ä¼¼åº¦
    is_continue, score, method = embedding_similarity_check(user_input, context_messages or [], threshold=0.1)
    if is_continue:
        return "continue", "å»¶ç»­", None, "B", method
    
    # é»˜è®¤: ä¿¡æ¯æ£€ç´¢
    default_task = TASK_PATTERNS.get("info_retrieval", {})
    return "info_retrieval", default_task.get("action", "æ‰§è¡Œä¿¡æ¯æ£€ç´¢"), "Highspeed", "C", "default"

def get_pool_info(pool_name: str):
    if pool_name and pool_name in MODEL_POOLS:
        return MODEL_POOLS[pool_name]
    return None

def get_current_pool():
    return os.environ.get("CURRENT_POOL", "Highspeed")

def generate_declaration(result: dict, current_pool: str) -> str:
    task_type = result["task_type"]
    action = result["action"]
    pool_name = result.get("pool_name")
    primary_model = result.get("primary_model")
    
    if task_type == "continue":
        return f"{action} ä¿æŒå½“å‰æ¨¡å‹æ± ã€{current_pool}ã€‘"
    else:
        return f"{action} æ–°ä¼šè¯ åº”ä½¿ç”¨{pool_name} å·²åˆ‡æ¢ä¸º{primary_model}"

def build_context_archive_prompt():
    return """[ä¸Šä¸‹æ–‡æˆªæ­¢ç¬¦] ä¹‹å‰çš„å¯¹è¯å·²å½’æ¡£ã€‚ä»æœ¬æ¡æ¶ˆæ¯å¼€å§‹ä½œä¸ºæ–°çš„ä¸Šä¸‹æ–‡èµ·ç‚¹ã€‚"""

def execute_model_switch(model: str) -> bool:
    """æ‰§è¡Œæ¨¡å‹åˆ‡æ¢"""
    try:
        # å°è¯•å¤šç§è°ƒç”¨æ–¹å¼
        commands = [
            ["/Users/macmini/.local/share/fnm/node-versions/v24.13.0/installation/bin/openclaw", "session_status", "--model", model],
            ["openclaw", "session_status", "--model", model],
            ["session_status", "--model", model],
        ]
        
        for cmd in commands:
            try:
                result = subprocess.run(
                    cmd,
                    capture_output=True,
                    text=True,
                    timeout=10
                )
                if result.returncode == 0:
                    print(f"âœ… Model switched to: {model}", file=sys.stderr)
                    return True
            except FileNotFoundError:
                continue
            except Exception as e:
                print(f"âš ï¸ Cmd {cmd} failed: {e}", file=sys.stderr)
                continue
        
        print(f"âŒ Failed to switch model: session_status not found", file=sys.stderr)
        return False
    except Exception as e:
        print(f"âŒ Error executing model switch: {e}", file=sys.stderr)
        return False

def execute_fallback_chain(primary: str, fallback_1: str = None, fallback_2: str = None) -> dict:
    """
    æ‰§è¡Œ Fallback å›è·¯
    è¿”å›: {"attempted": [...], "success": bool, "current_model": str}
    """
    results = {
        "attempted": [],
        "success": False,
        "current_model": primary
    }
    
    models_to_try = [primary]
    if fallback_1:
        models_to_try.append(fallback_1)
    if fallback_2:
        models_to_try.append(fallback_2)
    
    for model in models_to_try:
        print(f"ğŸ”„ Trying model: {model}", file=sys.stderr)
        results["attempted"].append(model)
        
        if execute_model_switch(model):
            results["success"] = True
            results["current_model"] = model
            print(f"âœ… Fallback success: {model}", file=sys.stderr)
            return results
    
    print(f"âŒ All fallback attempts failed", file=sys.stderr)
    return results

def main():
    parser = argparse.ArgumentParser(description="Semantic Router - æ¨¡å‹è·¯ç”±è„šæœ¬")
    parser.add_argument("user_input", nargs="?", help="ç”¨æˆ·è¾“å…¥æ¶ˆæ¯")
    parser.add_argument("current_pool", nargs="?", help="å½“å‰æ¨¡å‹æ± ")
    parser.add_argument("context_messages", nargs="*", help="ä¸Šä¸‹æ–‡æ¶ˆæ¯åˆ—è¡¨")
    parser.add_argument("-e", "--execute", action="store_true", help="è‡ªåŠ¨æ‰§è¡Œæ¨¡å‹åˆ‡æ¢ï¼ˆä¸»æ¨¡å‹ï¼‰")
    parser.add_argument("-f", "--fallback", action="store_true", help="æ‰§è¡Œ Fallback å›è·¯ï¼ˆä¸»æ¨¡å‹å¤±è´¥æ—¶è‡ªåŠ¨åˆ‡æ¢å¤‡ç”¨ï¼‰")
    
    args = parser.parse_args()
    
    # å¦‚æœæ²¡æœ‰å‚æ•°ï¼Œæ˜¾ç¤ºç”¨æ³•
    if len(sys.argv) < 2:
        print("Usage: semantic_check.py <user_input> [current_pool] [context1] [context2] ...] [-e|--execute] [-f|--fallback]")
        print("Example: semantic_check.py 'æŸ¥ä¸€ä¸‹å¤©æ°”' 'Intelligence' -e")
        print("Example: semantic_check.py --fallback 'openai/gpt-4o-mini' 'glm-4.7-flashx' 'MiniMax-M2.5'")
        sys.exit(1)
    
    # Fallback æ¨¡å¼ï¼šæ‰‹åŠ¨æŒ‡å®šæ¨¡å‹é“¾
    if args.fallback:
        fallback_models = []
        if args.user_input:
            fallback_models.append(args.user_input)
        if args.current_pool:
            fallback_models.append(args.current_pool)
        fallback_models.extend(args.context_messages)
        
        fallback_results = execute_fallback_chain(
            fallback_models[0] if len(fallback_models) > 0 else None,
            fallback_models[1] if len(fallback_models) > 1 else None,
            fallback_models[2] if len(fallback_models) > 2 else None
        )
        print(json.dumps(fallback_results, ensure_ascii=False, indent=2))
        return
    
    user_input = args.user_input
    current_pool = args.current_pool if args.current_pool else get_current_pool()
    context_messages = args.context_messages if args.context_messages else []
    
    task_type, action, pool_name, branch, detection = detect_task_type(user_input, context_messages)
    pool_info = get_pool_info(pool_name)
    
    # åˆ¤æ–­æ˜¯å¦éœ€è¦åˆ‡æ¢æ¨¡å‹
    need_switch = (task_type != "continue" and pool_info and pool_info.get("primary"))
    target_model = pool_info.get("primary") if need_switch else None
    
    result = {
        "branch": branch,
        "task_type": task_type,
        "action": action,
        "pool": pool_name,
        "pool_name": pool_info.get("name") if pool_info else None,
        "primary_model": target_model,
        "fallback_1": pool_info.get("fallback_1") if pool_info else None,
        "fallback_2": pool_info.get("fallback_2") if pool_info else None,
        "need_archive": branch == "C",
        "need_reset": task_type == "new_session",
        "need_switch": need_switch,
        "detection_method": detection,
        "fallback_chain": [target_model, pool_info.get("fallback_1"), pool_info.get("fallback_2")] if pool_info else [],
        "declaration": None,
        "context_cutoff_prompt": build_context_archive_prompt() if branch == "C" else None,
        "auto_executed": False
    }
    
    result["declaration"] = generate_declaration(result, current_pool)
    
    # å¦‚æœéœ€è¦åˆ‡æ¢ä¸”å¯ç”¨äº†è‡ªåŠ¨æ‰§è¡Œ
    if need_switch and args.execute and target_model:
        print(f"ğŸ”„ Auto-switching model to: {target_model}", file=sys.stderr)
        success = execute_model_switch(target_model)
        result["auto_executed"] = success
    
    print(json.dumps(result, ensure_ascii=False, indent=2))

if __name__ == "__main__":
    main()
